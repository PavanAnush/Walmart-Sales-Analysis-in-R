View(data)
View(iris)
library(sqldf)
data("UCBAdmissions")
View(UCBAdmissions)
sqldf(select Dept from x)
sqldf('select Dept from x')
sqldf("select * from x Where Admit ='Admitted' ")
sqldf("select * from X Where Admit ='Admitted' ")
sqldf("select * from UCBAdmissions Where Admit ='Admitted' ")
#Installing Packages
install.packages('clusterR')
#Installing Packages
install.packages('ClusterR')
install.packages('Cluster')
install.packages('cluster')
# Loading Package
library(ClusterR)
library(cluster)
iris_1 <- iris[, -5]
kmeans.re <- kmeans(iris_1,
centers = 3, nstart = 20)
#nstart means initial random number of
# centroids
# centers means no of clusters
# Cluster identification for
# each observation
kmeans.re$cluster
# confusion Matrix
cm <- table(iris$Species, kmeans.re$cluster)
cm
plot(iris_1[c("Sepal.Length", "Sepal.Width")],
col = kmeans.re$cluster,
main = "k-means with 3 clusters")
# Ploting Cluster Centers
kmeans.re$centers
kmeans.re$centers[, c("Sepal.Length", "Sepal.Width")]
# cexis font size, och is symbol
points(kmeans.re$centers[, c("Sepal.Length", "Sepal.Width")])
# cexis font size, och is symbol
points(kmeans.re$centers[, c("Sepal.Length", "Sepal.Width")],
col=1:3, pch =8, cex =3)
#Visulizing Clusters
y_kmeans <- kmeans.re$cluster
clusplot(iris_1[,c("Sepal.Length", "Sepal.Width")],
y_kmeans,
lines = 0,
shade = TRUE,
color = TRUE,
label = 2,
plotchar = FALSE,
span=TRUE,
main = paste("cluster iris"),
xlab = 'Sepal.Length',
ylab = 'Sepal.Width')
wbdc <- read.table(file.choose(), sep=",")
View(wbdc)
wbdc <- read.csv(file.choose(), sep=",")
View(wbdc)
wbdc <- wbdc[,-1]
View(wbdc)
data_norm <- function(x) {((x- min(x) / max(x)-min(x)))}
wbdc_norm <- as.data.frame(lapply(wbdc[,-1], data_norm))
View(wbdc_norm)
# Assuming 'your_dataset' is your dataset
dataset <- data.frame(
A = c(1, 2, NA, 4),
B = c(NA, 2, 3, 4),
C = c(1, 2, 3, 4)
)
dataset
# Remove NA values using mean imputation
rmdataset<- remove_na_mean(your_dataset)
rmdataset
# Using complete cases to remove NA values
datasetrm <- your_dataset[complete.cases(your_dataset), ]
datasetrm
# Install and load the 'arules' package
install.packages("arules")
library(arules)
# Assuming 'your_dataset' is your dataset
dataset <- data.frame(
A = c(1, 2, NA, 4),
B = c(NA, 2, 3, 4),
C = c(1, 2, 3, 4)
)
dataset
# Remove NA values using mean imputation
rmdataset<- remove_na_mean(your_dataset)
rmdataset
# Using complete cases to remove NA values
datasetrm <- your_dataset[complete.cases(your_dataset), ]
datasetrm
# Install and load the 'arules' package
install.packages("arules")
install.packages("arules")
library(arules)
# Assuming 'your_dataset' is your dataset
dataset <- data.frame(
A = c(1, 2, NA, 4),
B = c(NA, 2, 3, 4),
C = c(1, 2, 3, 4)
)
dataset
# Remove NA values using mean imputation
rmdataset<- remove_na_mean(your_dataset)
rmdataset
# Using complete cases to remove NA values
datasetrm <- your_dataset[complete.cases(your_dataset), ]
datasetrm
# Install and load the 'arules' package
install.packages("arules")
install.packages("arules")
# Assuming 'your_dataset' is your dataset
dataset <- data.frame(
A = c(1, 2, NA, 4),
B = c(NA, 2, 3, 4),
C = c(1, 2, 3, 4)
)
dataset
# Remove NA values using mean imputation
rmdataset<- remove_na_mean(your_dataset)
rmdataset
# Using complete cases to remove NA values
datasetrm <- your_dataset[complete.cases(your_dataset), ]
datasetrm
# Install and load the 'arules' package
install.packages("arules")
install.packages(c("binary", "packagers"))
# Assuming 'your_dataset' is your dataset
dataset <- data.frame(
A = c(1, 2, NA, 4),
B = c(NA, 2, 3, 4),
C = c(1, 2, 3, 4)
)
dataset
# Remove NA values using mean imputation
rmdataset<- remove_na_mean(your_dataset)
rmdataset
# Using complete cases to remove NA values
datasetrm <- your_dataset[complete.cases(your_dataset), ]
datasetrm
# Install and load the 'arules' package
install.packages("arules")
transactions <- list(
c("A", "B", "C"),
c("A", "B"),
c("A", "B", "C"),
c("B", "C")
)
transactions
# Convert the transactions to the 'transactions' class
transactions1 <- as(transactions, "transactions")
transactions1
# Apply the Apriori algorithm
min_support <- 0.3  # Set your minimum support threshold
rules <- apriori(transactions, parameter = list(support = min_support, minlen = 1, maxlen = 3))
min_support
rules
inspect(rules)
data <- read.csv("C:/Users/User/Downloads/groceries.csv")
data
data_no_na <- na.omit(data)
data_no_na
View(data_no_na)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
{
fileExt <- function(x) {
db <- grepl("\\.[^.]+\\.(gz|bz2|xz)$", x)
ans <- sub(".*\\.", "", x)
ans[db] <- sub(".*\\.([^.]+\\.)(gz|bz2|xz)$", "\\1\\2",
x[db])
ans
}
my_read_table <- function(...) {
lcc <- Sys.getlocale("LC_COLLATE")
on.exit(Sys.setlocale("LC_COLLATE", lcc))
Sys.setlocale("LC_COLLATE", "C")
read.table(...)
}
stopifnot(is.character(list))
names <- c(as.character(substitute(list(...))[-1L]), list)
if (!is.null(package)) {
if (!is.character(package))
stop("'package' must be a character vector or NULL")
}
paths <- find.package(package, lib.loc, verbose = verbose)
if (is.null(lib.loc))
paths <- c(path.package(package, TRUE), if (!length(package)) getwd(),
paths)
paths <- unique(normalizePath(paths[file.exists(paths)]))
paths <- paths[dir.exists(file.path(paths, "data"))]
dataExts <- tools:::.make_file_exts("data")
if (length(names) == 0L) {
db <- matrix(character(), nrow = 0L, ncol = 4L)
for (path in paths) {
entries <- NULL
packageName <- if (file_test("-f", file.path(path,
"DESCRIPTION")))
basename(path)
else "."
if (file_test("-f", INDEX <- file.path(path, "Meta",
"data.rds"))) {
entries <- readRDS(INDEX)
}
else {
dataDir <- file.path(path, "data")
entries <- tools::list_files_with_type(dataDir,
"data")
if (length(entries)) {
entries <- unique(tools::file_path_sans_ext(basename(entries)))
entries <- cbind(entries, "")
}
}
if (NROW(entries)) {
if (is.matrix(entries) && ncol(entries) == 2L)
db <- rbind(db, cbind(packageName, dirname(path),
entries))
else warning(gettextf("data index for package %s is invalid and will be ignored",
sQuote(packageName)), domain = NA, call. = FALSE)
}
}
colnames(db) <- c("Package", "LibPath", "Item", "Title")
footer <- if (missing(package))
paste0("Use ", sQuote(paste("data(package =", ".packages(all.available = TRUE))")),
"\n", "to list the data sets in all *available* packages.")
else NULL
y <- list(title = "Data sets", header = NULL, results = db,
footer = footer)
class(y) <- "packageIQR"
return(y)
}
paths <- file.path(paths, "data")
for (name in names) {
found <- FALSE
for (p in paths) {
tmp_env <- if (overwrite)
envir
else new.env()
if (file_test("-f", file.path(p, "Rdata.rds"))) {
rds <- readRDS(file.path(p, "Rdata.rds"))
if (name %in% names(rds)) {
found <- TRUE
if (verbose)
message(sprintf("name=%s:\t found in Rdata.rds",
name), domain = NA)
thispkg <- sub(".*/([^/]*)/data$", "\\1",
p)
thispkg <- sub("_.*$", "", thispkg)
thispkg <- paste0("package:", thispkg)
objs <- rds[[name]]
lazyLoad(file.path(p, "Rdata"), envir = tmp_env,
filter = function(x) x %in% objs)
break
}
else if (verbose)
message(sprintf("name=%s:\t NOT found in names() of Rdata.rds, i.e.,\n\t%s\n",
name, paste(names(rds), collapse = ",")),
domain = NA)
}
if (file_test("-f", file.path(p, "Rdata.zip"))) {
warning("zipped data found for package ", sQuote(basename(dirname(p))),
".\nThat is defunct, so please re-install the package.",
domain = NA)
if (file_test("-f", fp <- file.path(p, "filelist")))
files <- file.path(p, scan(fp, what = "",
quiet = TRUE))
else {
warning(gettextf("file 'filelist' is missing for directory %s",
sQuote(p)), domain = NA)
next
}
}
else {
files <- list.files(p, full.names = TRUE)
}
files <- files[grep(name, files, fixed = TRUE)]
if (length(files) > 1L) {
o <- match(fileExt(files), dataExts, nomatch = 100L)
paths0 <- dirname(files)
paths0 <- factor(paths0, levels = unique(paths0))
files <- files[order(paths0, o)]
}
if (length(files)) {
for (file in files) {
if (verbose)
message("name=", name, ":\t file= ...",
.Platform$file.sep, basename(file), "::\t",
appendLF = FALSE, domain = NA)
ext <- fileExt(file)
if (basename(file) != paste0(name, ".", ext))
found <- FALSE
else {
found <- TRUE
zfile <- file
zipname <- file.path(dirname(file), "Rdata.zip")
if (file.exists(zipname)) {
Rdatadir <- tempfile("Rdata")
dir.create(Rdatadir, showWarnings = FALSE)
topic <- basename(file)
rc <- .External(C_unzip, zipname, topic,
Rdatadir, FALSE, TRUE, FALSE, FALSE)
if (rc == 0L)
zfile <- file.path(Rdatadir, topic)
}
if (zfile != file)
on.exit(unlink(zfile))
switch(ext, R = , r = {
library("utils")
sys.source(zfile, chdir = TRUE, envir = tmp_env)
}, RData = , rdata = , rda = load(zfile,
envir = tmp_env), TXT = , txt = , tab = ,
tab.gz = , tab.bz2 = , tab.xz = , txt.gz = ,
txt.bz2 = , txt.xz = assign(name, my_read_table(zfile,
header = TRUE, as.is = FALSE), envir = tmp_env),
CSV = , csv = , csv.gz = , csv.bz2 = ,
csv.xz = assign(name, my_read_table(zfile,
header = TRUE, sep = ";", as.is = FALSE),
envir = tmp_env), found <- FALSE)
}
if (found)
break
}
if (verbose)
message(if (!found)
"*NOT* ", "found", domain = NA)
}
if (found)
break
}
if (!found) {
warning(gettextf("data set %s not found", sQuote(name)),
domain = NA)
}
else if (!overwrite) {
for (o in ls(envir = tmp_env, all.names = TRUE)) {
if (exists(o, envir = envir, inherits = FALSE))
warning(gettextf("an object named %s already exists and will not be overwritten",
sQuote(o)))
else assign(o, get(o, envir = tmp_env, inherits = FALSE),
envir = envir)
}
rm(tmp_env)
}
}
invisible(names)
}
data <- read.csv('C:/Users/HARI/Desktop/Rushi Project Question/Datasets.csv')
View(data)
is.na(data)
sum(is.na(data))
setwd('C:/Users/HARI/Desktop/PROJECTS/R projects')
# import the dataset
Walmart_sales <- read.csv('Walmart.csv')
View(Walmart_sales)
summary(Walmart_sales)
#For checking null or missing values
sum(is.na(Walmart_sales))
# -----------------------------------------------------------
#Time Series Analysis:
# Convert Date to Date type and sort the data
Walmart_sales$Date <- as.Date(Walmart_sales$Date, format = "%d-%m-%Y")
Walmart_sales <- Walmart_sales[order(Walmart_sales$Date),]
# Plot the time series
#plotting line plot
# If you set type = "l", it means you want to create a line plot
plot(Walmart_sales$Date, Walmart_sales$Weekly_Sales, type = "l")
#-----------------------------------------------------
#Calculating Correlation
cor(Walmart_sales$Fuel_Price, Walmart_sales$Weekly_Sales)
# Import library catools for spliting Data
library(caTools)
#Checking null Values if any
sum(is.na(Walmart_sales))
Walmart_split <- sample.split(Walmart_sales$Weekly_Sales, SplitRatio = 0.7)
str(Walmart_sales)
Walmart_train <- subset(Walmart_sales, split =TRUE)
Walmart_test <- subset(Walmart_sales, split = FALSE)
# Fitting multi Linear Regression Model
# Predicting "Weekly Sales" based on papameters Temperature, Fuel_Price,
# CPI,Unemployment
# Data Using Training data set of walmart sales
# Using 'lm' function to fit the regression model.
model <- lm(Weekly_Sales ~ Temperature + Fuel_Price + CPI + Unemployment,
data = Walmart_train)
summary(model)
# Using Predict function to predict the model.
test_model <- predict(model, data= Walmart_test)
test_model
# Calculate residuals
residuals <- Walmart_test$Weekly_Sales - test_model
# Plot a histogram of residuals
hist(residuals)
# Add a Quantile-Quantile plot
qqnorm(residuals)
qqline(residuals)
# Diagnostic plots
plot(model)
Fuel_Price = c(4.7,5.1,7.0,3 ),
# Prediction Using New data
df <- data.frame(Temperature = c(25.21, 28.11,30.30,20.05),
Fuel_Price = c(4.7,5.1,7.0,3 ),
CPI = c(130,211,145,215),
Unemployment = c(8,12,5,3))
result <- predict(model, df)
result
setwd('C:/Users/HARI/Desktop/PROJECTS/R projects')
# import the dataset
Walmart_sales <- read.csv('Walmart.csv')
View(Walmart_sales)
summary(Walmart_sales)
#For checking null or missing values
sum(is.na(Walmart_sales))
# -----------------------------------------------------------
#Time Series Analysis:
# Convert Date to Date type and sort the data
Walmart_sales$Date <- as.Date(Walmart_sales$Date, format = "%d-%m-%Y")
Walmart_sales <- Walmart_sales[order(Walmart_sales$Date),]
# Plot the time series
#plotting line plot
# If you set type = "l", it means you want to create a line plot
plot(Walmart_sales$Date, Walmart_sales$Weekly_Sales, type = "l")
#-----------------------------------------------------
#Calculating Correlation
cor(Walmart_sales$Fuel_Price, Walmart_sales$Weekly_Sales)
str(Walmart_sales)
#Checking null Values if any
sum(is.na(Walmart_sales))
# Import library catools for spliting Data
library(caTools)
Walmart_split <- sample.split(Walmart_sales$Weekly_Sales, SplitRatio = 0.7)
Walmart_train <- subset(Walmart_sales, split =TRUE)
Walmart_test <- subset(Walmart_sales, split = FALSE)
# Fitting multi Linear Regression Model
# Predicting "Weekly Sales" based on papameters Temperature, Fuel_Price,
# CPI,Unemployment
# Data Using Training data set of walmart sales
# Using 'lm' function to fit the regression model.
model <- lm(Weekly_Sales ~ Temperature + Fuel_Price + CPI + Unemployment,
data = Walmart_train)
summary(model)
# Using Predict function to predict the model.
test_model <- predict(model, data= Walmart_test)
test_model
# Calculate residuals
residuals <- Walmart_test$Weekly_Sales - test_model
# Plot a histogram of residuals
hist(residuals)
# Add a Quantile-Quantile plot
qqnorm(residuals)
qqline(residuals)
# Diagnostic plots
plot(model)
Fuel_Price = c(4.7,5.1,7.0,3 ),
# Prediction Using New data
df <- data.frame(Temperature = c(25.21, 28.11,30.30,20.05),
Fuel_Price = c(4.7,5.1,7.0,3 ),
CPI = c(130,211,145,215),
Unemployment = c(8,12,5,3))
result <- predict(model, df)
result
setwd('C:/Users/HARI/Desktop/PROJECTS/R projects')
# import the dataset
Walmart_sales <- read.csv('Walmart.csv')
View(Walmart_sales)
summary(Walmart_sales)
#For checking null or missing values
sum(is.na(Walmart_sales))
# -----------------------------------------------------------
#Time Series Analysis:
# Convert Date to Date type and sort the data
Walmart_sales$Date <- as.Date(Walmart_sales$Date, format = "%d-%m-%Y")
Walmart_sales <- Walmart_sales[order(Walmart_sales$Date),]
# Plot the time series
#plotting line plot
# If you set type = "l", it means you want to create a line plot
plot(Walmart_sales$Date, Walmart_sales$Weekly_Sales, type = "l")
#-----------------------------------------------------
#Calculating Correlation
cor(Walmart_sales$Fuel_Price, Walmart_sales$Weekly_Sales)
str(Walmart_sales)
#Checking null Values if any
sum(is.na(Walmart_sales))
# Import library catools for spliting Data
library(caTools)
Walmart_split <- sample.split(Walmart_sales$Weekly_Sales, SplitRatio = 0.7)
Walmart_train <- subset(Walmart_sales, split =TRUE)
Walmart_test <- subset(Walmart_sales, split = FALSE)
# Fitting multi Linear Regression Model
# Predicting "Weekly Sales" based on papameters Temperature, Fuel_Price,
# CPI,Unemployment
# Data Using Training data set of walmart sales
# Using 'lm' function to fit the regression model.
model <- lm(Weekly_Sales ~ Temperature + Fuel_Price + CPI + Unemployment,
data = Walmart_train)
summary(model)
# Using Predict function to predict the model.
test_model <- predict(model, data= Walmart_test)
test_model
# Calculate residuals
residuals <- Walmart_test$Weekly_Sales - test_model
# Plot a histogram of residuals
hist(residuals)
# Add a Quantile-Quantile plot
qqnorm(residuals)
qqline(residuals)
# Diagnostic plots
plot(model)
Fuel_Price = c(4.7,5.1,7.0,3 ),
result <- predict(model, df)
result
